{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-conditioned 3D Zero-Shot Self-Supervised Learning\n",
    "This code was adjusted from the original ZS-SSL Python implementation. For the original code, please visit https://github.com/byaman14/ZS-SSL-PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU server\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "# Libraries\n",
    "%matplotlib widget\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import sigpy as sp\n",
    "import sigpy.mri as mr\n",
    "import sigpy.plot as pl\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader \n",
    "from torchinfo import summary\n",
    "\n",
    "from codes import utils, parser_ops, mask_generator\n",
    "from codes.modules import MixL1L2Loss, Dataset, Dataset_Inference, train, validation, test\n",
    "from codes.model_3d import UnrolledNet\n",
    "\n",
    "# Ensure reproducibility\n",
    "utils.set_seeds(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "parser = parser_ops.get_parser()\n",
    "args = parser.parse_args([])\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image data\n",
    "img_data = np.load(args.data_dir)[None]\n",
    "args.ncontrast, args.nrow, args.ncol, args.ndepth = img_data.shape\n",
    "\n",
    "# Get training data\n",
    "kspace_train = utils.fftcn(img_data, axes=(-1,-2,-3)) \n",
    "\n",
    "# 1D ifft and normalize \n",
    "kspace_train = utils.ifftc1(kspace_train, axis=(-3))\n",
    "kspace_train = kspace_train / np.percentile(np.abs(kspace_train), 95)\n",
    "\n",
    "# Plotting\n",
    "pl.ImagePlot(img_data[..., 32], title=\"Fully sampled (R=1) data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrospective undersampling mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mask\n",
    "mask, true_accel_rate = mask_generator.generate_pdf_mask(\n",
    "    args.ndepth, args.ncol, accel=args.acc_rate, radius=0.125\n",
    ")\n",
    "mask = mask[None, None]\n",
    "\n",
    "# Plotting\n",
    "pl.ImagePlot(mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate validation mask and inputs for validation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate validation masks\n",
    "cv_trn_mask, cv_val_mask = utils.uniform_selection_3d(kspace_train, mask, rho=args.rho_val) \n",
    "remainder_mask, cv_val_mask = np.copy(cv_trn_mask), np.copy(cv_val_mask) \n",
    "\n",
    "# Generate validation data\n",
    "nw_input_val = utils.ifftc2(kspace_train * remainder_mask, axes=(-1,-2))\n",
    "ref_kspace_val = kspace_train * cv_val_mask\n",
    "\n",
    "pl.ImagePlot(nw_input_val[..., 32], z=0, title=\"Validation phase input\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate masks and  nw inputs for training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training masks and data\n",
    "train_shape = (args.num_reps, args.ncoil * args.ncontrast, args.nrow, args.ncol, args.ndepth)\n",
    "mask_shape = (args.num_reps, args.ncoil * args.ncontrast, 1, args.ncol, args.ndepth)\n",
    "\n",
    "nw_input_trn = np.empty(train_shape, dtype=np.complex64) \n",
    "ref_kspace = np.empty(train_shape, dtype=np.complex64) \n",
    "trn_mask = np.empty(mask_shape, dtype=np.complex64)\n",
    "loss_mask = np.empty(mask_shape, dtype=np.complex64) \n",
    "\n",
    "for jj in range(args.num_reps):\n",
    "    trn_mask[jj, ...], loss_mask[jj, ...] = utils.uniform_selection_3d(kspace_train, remainder_mask, rho=args.rho_train)\n",
    "    sub_kspace = kspace_train * trn_mask[jj]\n",
    "    ref_kspace[jj, ...] = kspace_train * loss_mask[jj]\n",
    "    nw_input_trn[jj, ...] = utils.ifftc2(sub_kspace, axes=(-1,-2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the training\n",
    "ref_kspace = utils.c2r(ref_kspace, axis=2).reshape(args.num_reps, -1, args.nrow, args.ncol, args.ndepth) \n",
    "nw_input_trn = utils.c2r(nw_input_trn, axis=2).reshape(args.num_reps, -1, args.nrow, args.ncol, args.ndepth) \n",
    "\n",
    "# Validation data \n",
    "ref_kspace_val = utils.c2r(ref_kspace_val, axis=1).reshape(-1, args.nrow, args.ncol, args.ndepth) \n",
    "nw_input_val = utils.c2r(nw_input_val, axis=1).reshape(-1, args.nrow, args.ncol, args.ndepth) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Train and Validation Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset(nw_input_trn, trn_mask, loss_mask, ref_kspace)\n",
    "train_loader = DataLoader(train_data, batch_size=args.batchSize, shuffle=True, num_workers=4)\n",
    "\n",
    "val_data = Dataset(nw_input_val[None], cv_trn_mask[None], cv_val_mask[None], ref_kspace_val[None])\n",
    "val_loader = DataLoader(val_data, batch_size=args.batchSize, shuffle=False, num_workers=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the directory, model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join('saved_models', f'T1w_R{args.acc_rate}_{args.nb_unroll_blocks}Unrolls_{args.nb_res_blocks}ResNet')\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "np.save(f\"mask.npy\", mask)\n",
    "\n",
    "model = UnrolledNet(args, device=device).to(device)\n",
    "loss_fn = MixL1L2Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "if args.transfer_learning:\n",
    "    TL_model = torch.load(f\"/exports/lkeb-hpc/mwjvanstraten/ZS-SSL/saved_models/pretrained/Pretraining_R{args.acc_rate}_5Unrolls_5ResNet/best.pth\", map_location=device)\n",
    "    model.load_state_dict(TL_model[\"model_state\"])\n",
    "    print(\"Pretrained weights loaded successfully.\")\n",
    "else:\n",
    "    print(\"No pretrained weights found. Starting from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a model summary\n",
    "summary(model, [\n",
    "    (args.batchSize, 2*args.ncoil*args.ncontrast, args.nrow, args.ncol, args.ndepth), # Input data\n",
    "    (args.batchSize, args.ncoil*args.ncontrast, 1, args.ncol, args.ndepth), # Train mask\n",
    "    (args.batchSize, args.ncoil*args.ncontrast, 1, args.ncol, args.ndepth), # Loss mask\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform 3D-ZS-SSL or 3D-ZS-SSL-TL training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_loss, total_val_loss = [], []\n",
    "valid_loss_min = np.inf\n",
    "ep, val_loss_tracker = 0, 0 \n",
    "\n",
    "# Train the model\n",
    "start_time = time.time()\n",
    "while ep < args.epochs and val_loss_tracker < args.stop_training:\n",
    "    tic = time.time()\n",
    "    trn_loss, lamdas, trn_kspace_output, trn_kspace_ref = train(train_loader, model, loss_fn, optimizer, device)\n",
    "    val_loss, val_kspace_output, val_kspace_ref = validation(val_loader, model, loss_fn, device=device)\n",
    "    total_train_loss.append(trn_loss)    \n",
    "    total_val_loss.append(val_loss)\n",
    "    \n",
    "    # Save the best checkpoint\n",
    "    checkpoint = {\n",
    "        \"epoch\": ep,\n",
    "        \"valid_loss_min\": val_loss,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optim_state\": optimizer.state_dict()\n",
    "    }\n",
    "    \n",
    "    if val_loss <= valid_loss_min:\n",
    "        valid_loss_min = val_loss\n",
    "        torch.save(checkpoint, os.path.join(directory, \"best.pth\")) \n",
    "        val_loss_tracker = 0 \n",
    "    else:\n",
    "        val_loss_tracker += 1\n",
    "\n",
    "    toc = time.time() - tic\n",
    "    sio.savemat(os.path.join(directory, 'TrainingLog.mat'), {'trn_loss': total_train_loss, 'val_loss': total_val_loss})\n",
    "    print(f\"Epoch: {ep+1}, elapsed_time={toc:.2f}, trn loss={trn_loss:.3f}, val loss={val_loss:.3f}\")\n",
    "\n",
    "    if ep % 5 == 0:\n",
    "        # Inference snapshot\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_mask = np.complex64(mask)\n",
    "            nw_input_inference = utils.ifftc2(kspace_train*test_mask, axes=(-1,-2))\n",
    "            ref_image = utils.ifftc2(kspace_train, axes=(-1,-2))\n",
    "\n",
    "            nw_input_inference_real = utils.c2r(nw_input_inference, axis=1).reshape(-1, args.nrow, args.ncol, args.ndepth)\n",
    "            test_data = Dataset_Inference(\n",
    "                nw_input_inference_real[np.newaxis],\n",
    "                test_mask[np.newaxis]\n",
    "            )\n",
    "            test_loader = DataLoader(test_data, batch_size=args.batchSize, shuffle=False, num_workers=0)\n",
    "\n",
    "            zs_ssl_recon = test(test_loader, model, device)\n",
    "            zs_ssl_recon = utils.r2c(zs_ssl_recon.squeeze().reshape(args.ncoil*args.ncontrast, 2, args.nrow, args.ncol, args.ndepth).to('cpu').numpy(), axis=1)\n",
    "\n",
    "        # Calculate SSIM & PSNR\n",
    "        slice_range = range(16, 38) \n",
    "        ssim_scores, psnr_scores = [], []\n",
    "\n",
    "        for sl in slice_range:\n",
    "            ref_slice = np.abs(ref_image[..., sl])\n",
    "            recon_slice = np.abs(zs_ssl_recon[..., sl])\n",
    "\n",
    "            ssim_vals = utils.ssim_batch(ref_slice, recon_slice)\n",
    "            psnr_vals = utils.psnr_batch(ref_slice, recon_slice)\n",
    "\n",
    "            ssim_scores.append(np.mean(ssim_vals))\n",
    "            psnr_scores.append(np.mean(psnr_vals))\n",
    "\n",
    "        mean_ssim = np.mean(ssim_scores)\n",
    "        mean_psnr = np.mean(psnr_scores)\n",
    "\n",
    "        print(f\"Epoch {ep+1} | SSIM (slices 17â€“38): {mean_ssim:.4f}, PSNR: {mean_psnr:.2f} dB\")\n",
    "            \n",
    "    ep += 1\n",
    "    \n",
    "end_time = time.time()\n",
    "print('Training completed in  ', str(ep), ' epochs, ',((end_time - start_time) / 60), ' minutes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mr_recon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
